## Simple Information Retrieval System using BM25 model

### System Structure

```
├─COMP3009J-corpus-large
│  ├─documents
│  ├─files
│  ├─index.json
│  ├─output.txt
│  ├─README.md
│  └─large-corpus.py   
└─COMP3009J-corpus-small
│   ├─documents
│   ├─files
│   ├─index.json
│   ├─output.txt
│   ├─README.md
│   └─small-corpus.py
└─README.md
```

### 1. How to use the system

There are two python file provided from both small and large corpus. You can move to the different directory and use command line to execute search on the corpus.

#### For large corpus

You can move to the `COMP3009J-corpus-large` directory and enter the following command in the command line to execute manual search

```
python large-corpus.py -m manual
```

Then you can enter a query and type `enter` in the end. The system will return the top 15 relevant document with document names and scores. (If the documents will be returned are less than 15, return all of them)

You can enter the following command  in the command line to execute evaluation

```
python large-corpus.py -m evaluation
```

Then the `output.txt` will be created that contains the returned result of the 150 queries. The average score of 7 evaluation metrics will also be printed.

#### For small corpus

You can move to the `COMP3009J-corpus-small` directory and enter the following command in the command line to execute manual search

```
python small-corpus.py -m manual
```

Then you can enter a query and type `enter` in the end. The system will return the top 15 relevant document with document names and scores. (If the documents will be returned are less than 15, return all of them)

You can enter the following command  in the command line to execute evaluation

```
python small-corpus.py -m evaluation
```

Then the `output.txt` will be created that contains the returned result of the 225 queries. The average score of 7 evaluation metrics will also be printed.

### 2. System Efficiency

The efficiency test is conducted on a PC with Windows 10.

CPU: Core i7-9750H

Memory: 16GB

#### For large corpus

Index create and store time: 	***about 35s***

Index load time: 						 ***about 1.5s***

Manual query execute time:     ***about 0.03s***

Evaluation execute time:           ***about 1.75s***

#### For small corpus

Index create and store time: 	***about 1.2s***

Index load time: 						 ***about 0.03s***

Manual query execute time:     ***about 0.01s***

Evaluation execute time:           ***about 1.7s***

### 3. Design Decision

Some decisions were made for both precision issue and efficiency issue in the system.

#### Decisions for precision issue

##### 1. tokenisation

The tokenisation strategy is to remove all punctuations and other marks except hyphen(-).  That is realized by the regular expression to substitute the symbol except letter, number, space, and hyphen to space, then split the string. That can make sure that all useless punctuations and marks are removed, at the same time, spaces are left. After the split process, the string on the left side of the punctuation and the string on the right side can be divided. That can help in some scenarios like **URL** split. 

##### 2. number of result returns

The consistent number of returned result is chosen at the beginning. However, the real relevant document distribution in the returned result is affected by both query length and the number of document contained in the corpus. The result score of the BM25 model is a none-linear one. More matches appear, more scores are added to the result score. It means that the short query has less words to match, so the result score can't be vary and the real relevant document can distribute from the top to the end. In contrast, long query has more words to match. The result score can be vary and the real relevant document can be quite concentrated at the top if the some of the important words are matched. To fit this trend, a inverse ratio is introduced to return more result for short query and less result for long query. The ratio is also depends on the number of document contained in the corpus. A large ratio is better for a large corpus and a small ratio is fit for a small one as well.

#### Decision for efficiency issue

##### 1. stemming speed

The porter for stemming is quite slow, so a dictionary that stores all token met before and the term for it after stemming is created. If a token has been stemmed before, we can check the dictionary and get the term of it after the stemming. If a token hasn't been stemmed, we should process the stemming and add it with term to the dictionary. That promote the efficiency significantly.

##### 2. pre-calculation

After each term in the query is generated, a temporary calculation dictionary is created to store the term and the pre-calculated score for this term. The pre-calculated score is generated by:
$$
(1+k)\times\log{(\frac{N-n_i+0.5}{n_i+0.5})}
$$

 In the calculation process for terms in each document, the system only need to generate the rest part of the BM25 calculation for each term and then multiply it by the pre-calculated part. Then, it can add the score of each term together to get the score of the current document. The pre-calculation can save times by preventing redundant calculation for same term in different documents. The effect of this design can increase when the corpus increase.